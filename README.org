
* GCDObsidian
  + Embedded DSL for implementation of GPU Kernels
  + Generates CUDA kernels
    
* News in GCDObsidian 
  + Sync can be performed on groups of arrays. This leads 
    to that a number of threads equal to the GCD of the lengths of
    the arrays is used to compute and store them. 
  + The Sync concept will gradually be replaced by a group 
    of functions, "store" functions. 
  + Kernel Building blocks: 
    There are pure functions, (Array a -> Array a), that can be composed
    using Haskell functional composition. These are turned into "kernels" using the function pure.
    There are built in kernel building blocks, (things like, Array a -> Kernel (Array a)).
    These represents (hopefully) efficient ways to store intermediate values 
    in GPU shared memory. (store, storeIlv, storeIlvF, storeP - currently) 

    
* Work in progress
  + OpenCL generation is unfinished
  + CUDA generation is "untested" 
  + More library functions needed
  
* Thoughts 
  + replace sync with a bunch of functions describing various ways to 
    "Store" data into GPU shared memory.
  +  store arr       = old sync
  +  storeP (arr1,arr2) = GCD of lengths number of threads used
  +  storeIlv (arr of pairs) = forces the elements in the pairs to be interleaved in memory (could be extremely innefficient if sizes differ)
  +  storeIlvF (arr of pairs) = same as above but gives a flat array back 
    
